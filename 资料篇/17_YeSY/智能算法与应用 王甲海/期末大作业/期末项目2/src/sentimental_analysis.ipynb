{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentimental_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOtBzxuzcyvw2GvuL24XwOt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L-72Ql-jxaDO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594524012079,"user_tz":-480,"elapsed":16542,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}},"outputId":"fd1502d5-c0f3-4a27-b57e-acadff9532d4"},"source":["# 绑定谷歌硬盘，导入数据\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DeJjPT8p1PRy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594524035741,"user_tz":-480,"elapsed":40194,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}}},"source":["# 更改当前路径\n","import os\n","import pandas as pd\n","path = \"/content/drive/My Drive/Movie Sentimental Analysis\"\n","os.chdir(path)\n","\n","# Any results you write to the current directory are saved as output.\n","import torch\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import numpy as np\n","import random\n","import pickle\n","from tqdm import tqdm\n","from collections import Counter\n","from torch.utils.data import DataLoader,Dataset\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from sklearn.metrics import accuracy_score\n","\n","# 判断是否使用了gpu\n","import tensorflow as tf\n","tf.test.gpu_device_name()\n","\n","# 读取数据\n","train = pd.read_csv('train.tsv', sep='\\t')\n","\n","# 标签数据\n","train_labels = torch.tensor(train['Sentiment'].values)   # 训练集标签"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqR3_2VgKeqg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1594524039729,"user_tz":-480,"elapsed":44177,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}},"outputId":"182ce02c-2420-45d1-8ec5-00c9528f827b"},"source":["def Corpus_Extr(df):\n","    print('Construct Corpus...')\n","    corpus = []\n","    # 将phrase分为一个个词语\n","    for i in tqdm(range(len(df))):\n","        corpus.extend(df.Phrase[i].lower().split())\n","    corpus = Counter(corpus)\n","    corpus2 = sorted(corpus,key=corpus.get,reverse=True)\n","    print('Convert Corpus to Integers')\n","    # 构建word:int字典\n","    vocab_to_int = {word: idx for idx,word in enumerate(corpus2,1)}\n","    # 构建int:word字典\n","    int_to_vocab = {idx : word for idx,word in enumerate(corpus2,1)}\n","    print('Convert Phrase to Integers')\n","    phrase_to_int = []\n","    # 将phrase的词语列表替换为int列表\n","    for i in tqdm(range(len(df))):\n","        phrase_to_int.append([vocab_to_int[word] for word in df.Phrase.values[i].lower().split()])\n","    return corpus, vocab_to_int, int_to_vocab, phrase_to_int\n","corpus, vocab_to_int,int_to_vocab, phrase_to_int = Corpus_Extr(train)\n","\n","\n","# 对于不存在的词语用'<unk>'来表示\n","vocab_to_int['<unk>'] = 0\n","int_to_vocab[0] = '<unk>'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["  3%|▎         | 5133/156060 [00:00<00:02, 51326.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Construct Corpus...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 156060/156060 [00:02<00:00, 56873.96it/s]\n","  9%|▊         | 13507/156060 [00:00<00:01, 135068.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["Convert Corpus to Integers\n","Convert Phrase to Integers\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 156060/156060 [00:01<00:00, 115329.16it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Fk6fiKzFGzm0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594524070319,"user_tz":-480,"elapsed":74762,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}},"outputId":"18a2ff39-9edd-4cd7-d031-a5d812fac687"},"source":["# 读取预训练的语言模型  glove-100\n","def read_glove():\n","    print(\"reading glove...\")\n","    glove = {}\n","    with open(\"glove.txt\", \"r\") as f:\n","        for line in f.readlines():\n","            line=line.split()\n","            word = line[0]\n","            vector = np.array(line[1:]).astype(np.float)\n","            # 如果该词语在词典中存在\n","            if vocab_to_int.get(word, -1) != -1:\n","                glove[vocab_to_int[word]] = vector\n","    # 定义glove[0] <unk>为0\n","    glove[0] = [0]*100\n","    return glove\n","# 读取glove模型\n","glove = read_glove()\n","\n","# 将phrase padding 为相同的长度，多删少补\n","def Pad_sequences(phrase_to_int,seq_length):\n","    print(\"padding phrase\")\n","    pad_sequences = np.zeros((len(phrase_to_int), seq_length),dtype=int)\n","    for idx,row in tqdm(enumerate(phrase_to_int),total=len(phrase_to_int)):\n","        pad_sequences[idx, :len(row)] = np.array(row)[:seq_length]\n","    return pad_sequences\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["reading glove...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LlE6S5rFz3cj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594533492589,"user_tz":-480,"elapsed":994,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}}},"source":["# 构建model\n","class LSTM(nn.Module):\n","    def __init__(self,hidden_dim, linear_dim, n_word, n_layers,embed_dim, weight, labels):\n","        super().__init__()\n","        self.n_layers = n_layers    # lstm层数\n","        self.hidden_dim = hidden_dim    # 隐藏层节点数\n","        self.embedd_dim = embed_dim   # 使用glove的数据\n","        self.lables = labels # softmax要划分的类别数\n","        self.linear_dim = linear_dim # 线形层的节点数\n","        self.n_word = n_word # 词语总数\n","        \n","        # 定义词嵌入层，使用预训练glove模型来进行\n","        self.embedding = nn.Embedding.from_pretrained(weight)\n","        self.embedding.weight.requires_grad = False\n","\n","        # # 不使用glove，直接进行词语嵌入\n","        self.embedding = nn.Embedding(self.n_word, 100)\n","\n","        # 定义双层的LSTM层\n","        self.lstm = nn.LSTM(self.embedd_dim, self.hidden_dim,num_layers = self.n_layers, bidirectional=True)\n","\n","        # 定义线形层 使用relu激活函数 因为对lstm的输出进行了拼接，因此这里输入维度是hidden_dim*2\n","        self.linear = nn.Sequential(\n","            nn.Linear(self.hidden_dim * 2, self.linear_dim),\n","            nn.ReLU(True),\n","        )\n","\n","        # 定义全连接层\n","        self.fc = nn.Linear(self.linear_dim, self.lables)\n","\n","        \n","    def forward(self, inputs):\n","        embeddings = self.embedding(inputs)\n","        # permute [batch_size, seq_len, embedded_size] -> [seq_len, batch_size, embedded_size]\n","        lstm_out, hidden = self.lstm(embeddings.permute([1, 0, 2]))\n","        output = self.linear(lstm_out[-1])\n","        output = self.fc(output)\n","        return output\n"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHDNzdrflLjK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1594534594290,"user_tz":-480,"elapsed":1536,"user":{"displayName":"brandon ye","photoUrl":"","userId":"12094399851862689653"}},"outputId":"8ab295cd-ac22-4bf8-cad1-13a4fb779368"},"source":["labels = 5  # 要划分类别数\n","num_epochs = 5\n","embed_dim = 100\n","hidden_dim = 128\n","linear_dim = 64\n","n_layers = 2\n","batch_size = 64\n","lr = 0.001\n","device = torch.device('cuda:0')\n","\n","\n","# 读取glove模型\n","weight = torch.zeros(len(vocab_to_int), embed_dim)\n","count = 0 \n","for i in range(len(vocab_to_int)):\n","        # 若该词语不存在，通<unk>的值\n","        if i not in glove.keys():\n","            count+=1\n","        weight[i, :] = torch.Tensor(glove.get(i,np.random.rand(1,100)))\n","    \n","# 整理训练数据\n","train_features = torch.LongTensor(Pad_sequences(phrase_to_int,30))\n","\n","train_set = torch.utils.data.TensorDataset(train_features, train_labels)\n","#train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True)\n","train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n","\n","net = LSTM(hidden_dim, linear_dim, len(vocab_to_int),n_layers,embed_dim, weight, labels)\n","\n","net.to(device)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=lr)\n","# 动态调整学习率，每隔step_size就将学习率调整为0.1倍\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 40, gamma=0.1, last_epoch=-1)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/156060 [00:00<?, ?it/s]\u001b[A\n"," 27%|██▋       | 42127/156060 [00:00<00:00, 421250.31it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["padding phrase\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 52%|█████▏    | 80981/156060 [00:00<00:00, 410872.36it/s]\u001b[A\n","100%|██████████| 156060/156060 [00:00<00:00, 413783.37it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z4F-VdXYtgkP","colab_type":"code","colab":{}},"source":["# 训练模型\n","from torch.autograd import Variable\n","global_batch_size = 0 # 全局的batchnum统计\n","for epoch in range(num_epochs):\n","    start = time.time()\n","    train_loss, test_losses = 0, 0\n","    train_acc, test_acc = 0, 0\n","    n, m = 0, 0\n","    batch_num = 0\n","    for feature, label in train_iter:\n","        n += 1\n","        batch_num +=1\n","        global_batch_size+=1\n","        net.zero_grad()\n","        feature = Variable(feature.cuda())\n","        label = Variable(label.cuda())\n","        score = net(feature)\n","        loss = loss_function(score, label)\n","        loss.backward()\n","        optimizer.step()\n","        train_acc += accuracy_score(torch.argmax(score.data.cpu(), dim=1), label.cpu())\n","        train_loss += loss\n","        \n","        if batch_num %100 ==0:\n","            print('batch_num: %d, train loss: %.4f, train acc: %.2f'%\n","                        (batch_num, train_loss / n, train_acc / n))\n","            \n","    scheduler.step()    # 更新学习率\n","    cur_lr = optimizer.param_groups[0]['lr']    # 查看当前学习率\n","    end = time.time()\n","    runtime = end - start\n","    print('epoch: %d, train loss: %.4f, train acc: %.2f, time: %.2f, learning rate: %f' %\n","          (epoch, train_loss / n, train_acc / n, runtime, cur_lr))\n","\n","torch.save(net, 'network.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3o1UiGPomSiR","colab_type":"code","colab":{}},"source":["plt.figure()\n","plt.plot(x_batch,y64_loss, label='batch_size=64')\n","plt.plot(x_batch,y128_loss, label='batch_size=128')\n","plt.plot(x_batch,y256_loss, label='batch_size=256')\n","plt.legend()\n","plt.xlabel('batch_num')\n","plt.ylabel('loss')\n","plt.savefig('training_batch_size.png', format='png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAwl78FRDeRI","colab_type":"code","colab":{}},"source":["# 绘制图像\n","import matplotlib.pyplot as plt \n","# 损失函数\n","plt.figure()\n","plt.plot(x_epoch,y_loss, color='m')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.savefig('training_loss.png', format='png')\n","\n","# 精确度\n","plt.figure()\n","plt.plot(x_epoch,y_acc, color='y')\n","plt.xlabel('epoch')\n","plt.ylabel('acc')\n","plt.savefig('training_acc.png', format='png')\n","\n","# 学习率变化情况\n","plt.figure()\n","plt.plot(x_epoch,y_lr)\n","plt.xlabel('epoch')\n","plt.ylabel('lr')\n","plt.savefig('training_lr.png', format='png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tG6WVmcMCvoO","colab_type":"code","colab":{}},"source":["import csv\n","# 测试数据集\n","f = open('submission.csv', 'w', newline='') # 要写入的测试文件\n","writer = csv.writer(f)\n","writer.writerow(['PhraseId', 'Sentiment'])\n","net = torch.load('network.pkl').cuda()  # 加载模型\n","\n","# 读取测试数据\n","df = pd.read_csv('test.tsv', sep='\\t')\n","test_phrase_to_int = []\n","# 将phrase的词语列表替换为int列表   如果词语不存在则用0代替\n","for i in range(len(df)):\n","    test_phrase_to_int.append([vocab_to_int.get(word, 0) for word in df.Phrase.values[i].lower().split()])\n","# 对数据进行padding\n","test_phrase_to_int = Pad_sequences(test_phrase_to_int,30)\n","\n","# 遍历测数据计算结果\n","id = 156061\n","for i in range(len(test_phrase_to_int)):\n","    if i % 3000 ==0:\n","        print(\"======>\",i)\n","    feature = torch.LongTensor(test_phrase_to_int[i])\n","    feature = torch.unsqueeze(feature, dim=0)\n","    feature = Variable(feature.cuda())\n","    score = net(feature)\n","    res = torch.argmax(score.data.cpu())\n","    writer.writerow([id, res.item()])\n","    id += 1\n","f.close()\n","    "],"execution_count":null,"outputs":[]}]}